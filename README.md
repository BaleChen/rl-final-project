# Qualitative and Quantitative Analysis of Configurating SAC Algorithm with REDQ and Reset Mechanism

This project is my final project of CSCI-SHU 375 Reinforcement Learning with Prof. Keith Ross, in Fall 2022. Please contact me at `bale.chen[at]nyu.edu` for any questions.

* This paper explores the application of Randomized Ensembled Double-Q Learning (REDQ) and a reset mechanism to the Soft-Actor Critics (SAC) algorithm in deep reinforcement learning, resulting in significant improvements in sample efficiency and performance on the Hopper-v3 and HalfCheetah-v3 environments.

## Project Report & Scripts

Please refer to `Bale_Chen_RL_Final_Project_Report.pdf` and `script` folder.

## Footnote

The code templetes are supported by TA Watcher Wang, and the process is supervised by Prof. Keith Ross. This work was also supported in part through the NYU IT High Performance Computing resources, services, and staff expertise. 
